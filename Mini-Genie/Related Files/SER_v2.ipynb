{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GpAxVkwwHrK0"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "import os\n",
        "import sys\n",
        "import pickle\n",
        "\n",
        "import librosa\n",
        "import librosa.display\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from IPython.display import Audio\n",
        "\n",
        "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "import keras\n",
        "from keras.callbacks import ReduceLROnPlateau\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Conv1D, MaxPooling1D, Flatten, Dropout, BatchNormalization\n",
        "from keras.utils import np_utils, to_categorical\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from tensorflow.keras.models import load_model"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import soundfile\n",
        "import numpy as np\n",
        "import librosa\n",
        "import glob\n",
        "import os # to use operating system dependent functionality\n",
        "from sklearn.model_selection import train_test_split # for splitting training and testing\n",
        "from sklearn.neural_network import MLPClassifier # multi-layer perceptron model\n",
        "from sklearn.metrics import accuracy_score # to measure how good we are"
      ],
      "metadata": {
        "id": "LlvdI97sH-rW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<h1>Dataset"
      ],
      "metadata": {
        "id": "27QoNwopiD6s"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#RAVDESS\n",
        "!gdown 13NCkIfuEJ-rgEQbqPo4CI31aBUQ2Mc77\n",
        "!unzip \"/content/archive (1).zip\" -d \"/content/ravdess_dataset/\""
      ],
      "metadata": {
        "id": "ZLrB21FCIcIc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<h1>Version 2</h1>"
      ],
      "metadata": {
        "id": "wplBiOY4fh-i"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#def get_feature(file_name,mfccs,mel,chroma,contrast):\n",
        "\n",
        "def get_feature(file_name):\n",
        "\n",
        "        data, sample_rate = librosa.load(file_name)\n",
        "        stft = np.abs(librosa.stft(data))\n",
        "        mfccs = np.mean(librosa.feature.mfcc(y=data, sr=sample_rate, n_mfcc=40).T, axis=0)\n",
        "        mel = np.mean(librosa.feature.melspectrogram(y=data, sr=sample_rate).T,axis=0)\n",
        "        chroma = np.mean(librosa.feature.chroma_stft(S=stft, sr=sample_rate).T,axis=0)\n",
        "        contrast = np.mean(librosa.feature.spectral_contrast(S=stft, sr=sample_rate).T,axis=0)\n",
        "\n",
        "\n",
        "\n",
        "        return mfccs,mel,chroma,contrast"
      ],
      "metadata": {
        "id": "06TH8s3WICM8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# emotions in dataset\n",
        "list_emotion = {\n",
        "    \"01\": \"neutral\",\n",
        "    \"02\": \"calm\",\n",
        "    \"03\": \"happy\",\n",
        "    \"04\": \"sad\",\n",
        "    \"05\": \"angry\",\n",
        "    \"06\": \"fearful\",\n",
        "    \"07\": \"disgust\",\n",
        "    \"08\": \"surprised\"\n",
        "}\n",
        "\n",
        "# I am using only 3 emotions to observe,feel free to add more.\n",
        "classify_emotions = {\n",
        "    \"neutral\",\n",
        "    \"calm\",\n",
        "    \"happy\",\n",
        "    \"sad\",\n",
        "    \"angry\",\n",
        "    \"fearful\",\n",
        "    \"surprised\"\n",
        "}"
      ],
      "metadata": {
        "id": "dWJRrMYPIE_7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def load_data(test_size=0.2):\n",
        "    feature, y = [], []\n",
        "\n",
        "    for file in glob.glob(\"/content/ravdess_dataset/Actor_*//*.wav\"):\n",
        "        basename = os.path.basename(file)  # get the base name of the audio file\n",
        "\n",
        "        emotion = list_emotion[basename.split(\"-\")[2]]   # get the emotion label\n",
        "\n",
        "        if emotion in classify_emotions:    # we allow only classify_emotions we set\n",
        "            mfccs,mel,chroma,contrast = get_feature(file)\n",
        "\n",
        "            ext_features = np.hstack([mfccs,mel,chroma,contrast])\n",
        "            feature.append(ext_features)\n",
        "            y.append(emotion)\n",
        "\n",
        "    # split the data to training and testing and return it\n",
        "    return train_test_split(np.array(feature), y, test_size=test_size, random_state=9)"
      ],
      "metadata": {
        "id": "DO2lUEsmIvZr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "feature_train, feature_test, y_train, y_test = load_data(0.8)"
      ],
      "metadata": {
        "id": "G3ty8QISMOJG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# using get_features() function\n",
        "print(\"Number of samples in training data:\", feature_train.shape[0])\n",
        "\n",
        "print(\"Number of samples in testing data:\", feature_test.shape[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kU1bIyJCPedj",
        "outputId": "3b4f1791-3d1d-456b-ae9a-f74ad030a62e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of samples in training data: 873\n",
            "Number of samples in testing data: 375\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Training the model.....\")\n",
        "clf=MLPClassifier(alpha=0.01, batch_size=256, epsilon=1e-08, hidden_layer_sizes=(300,), learning_rate='adaptive', max_iter=500).fit(feature_train, y_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YmjUBGZuI9eY",
        "outputId": "5a8a9d3e-28b4-49a4-9140-06acbc2e93a1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training the model.....\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PaqpxW3xTOr5",
        "outputId": "69c9fef1-a89b-4183-c8e6-2f47bd57bdc3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import joblib\n",
        "joblib.dump(clf,'/content/gdrive/MyDrive/Projects/CSE 4622 ML/model\\\\emotion_detection_from_audio_v2.h5')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fP1hqxRQT4nT",
        "outputId": "b810910e-c14f-40fb-a220-60987bc7018d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['/content/gdrive/MyDrive/Projects/CSE 4622 ML/model\\\\emotion_detection_from_audio_v2.h5']"
            ]
          },
          "metadata": {},
          "execution_count": 72
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# predict 25% of data\n",
        "y_pred = clf.predict(feature_test)\n",
        "\n",
        "# calculate the accuracy\n",
        "accuracy = accuracy_score(y_true=y_test, y_pred=y_pred)\n",
        "\n",
        "print(\"Accuracy is: {:.2f}%\".format(accuracy*100))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZSUprhqRPoij",
        "outputId": "6632f2e0-eaa1-47c0-8eaa-e1114ca15f95"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy is: 50.93%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Number of features:\", feature_train.shape[1])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bCpqoYq8Ptsu",
        "outputId": "ac062f1d-8b34-40f5-83ad-5311f59b6dc5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of features: 187\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "path_ = '/content/ravdess_dataset/Actor_03/03-01-07-02-01-02-03.wav'\n",
        "feature_=[]\n",
        "\n",
        "mfccs,mel,chroma,contrast = get_feature(path_)\n",
        "ext_features_ = np.hstack([mfccs,mel,chroma,contrast])\n",
        "feature_.append(ext_features_)\n",
        "\n",
        "y_pred_ = clf.predict(feature_)\n",
        "#y_pred_ = encoder.inverse_transform(pred_test_)\n",
        "print(y_pred_) #emotion prediction\n",
        "print(y_pred_[0]) #emotion prediction"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lbWSx2MIP8IS",
        "outputId": "be3aadad-5306-47f1-d891-8dfc976e902d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['angry']\n",
            "angry\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<h2>Version 3"
      ],
      "metadata": {
        "id": "XIBlhbQEV3Sc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Total number of training sample: \",feature_train.shape[0])\n",
        "print(\"Total number of testing example: \",feature_test.shape[0])\n",
        "print(\"Feature extracted\",feature_train.shape[1])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KlvCNXV2XftC",
        "outputId": "e7a13cff-c9d1-45d0-b2cd-3497ef7d1d5b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total number of training sample:  249\n",
            "Total number of testing example:  999\n",
            "Feature extracted 187\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.datasets import imdb\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.layers import LSTM\n",
        "from tensorflow.keras.layers import Embedding\n",
        "from tensorflow.keras.preprocessing import sequence\n",
        "# fix random seed for reproducibility\n",
        "tf.random.set_seed(7)\n",
        "sent_length = 5000\n",
        "\n",
        "# truncate and pad input sequences\n",
        "voc_size=10000"
      ],
      "metadata": {
        "id": "5MvtRgIVafVt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "embedding_vector_features=40\n",
        "\n",
        "model=Sequential()\n",
        "model.add(Embedding(voc_size,embedding_vector_features,input_length=sent_length))\n",
        "model.add(Dropout(0.3))\n",
        "model.add(LSTM(100)) #Adding 100 lstm neurons in the layer\n",
        "model.add(Dropout(0.3))\n",
        "model.add(Dense(1,activation='sigmoid'))\n",
        "\n",
        "#Compiling the model\n",
        "model.compile(loss='binary_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
        "print(model.summary())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LA_WGRRmbt2h",
        "outputId": "6731af88-9c09-4874-b2ab-1da7a5e6fe90"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_5\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding_3 (Embedding)     (None, 5000, 40)          400000    \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 5000, 40)          0         \n",
            "                                                                 \n",
            " lstm_3 (LSTM)               (None, 100)               56400     \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 100)               0         \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 1)                 101       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 456,501\n",
            "Trainable params: 456,501\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "feature_train = np.array(feature_train)\n",
        "y_train = np.array(y_train)\n",
        "feature_test = np.array(feature_test)\n",
        "y_test = np.array(y_test)"
      ],
      "metadata": {
        "id": "GG3thhXkd7Wh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(feature_train,y_train,validation_data=(feature_test,y_test),epochs=10,batch_size=64)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 762
        },
        "id": "GTf0NgZMaVGf",
        "outputId": "67ad373b-670f-46c6-a483-9ce85ebdc420"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-113-04d6011a8f19>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeature_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeature_test\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m64\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     68\u001b[0m             \u001b[0;31m# To get the full stack trace, call:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m             \u001b[0;31m# `tf.debugging.disable_traceback_filtering()`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m             \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mtf__train_function\u001b[0;34m(iterator)\u001b[0m\n\u001b[1;32m     13\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m                     \u001b[0mdo_return\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m                     \u001b[0mretval_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconverted_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep_function\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfscope\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m                 \u001b[0;32mexcept\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m                     \u001b[0mdo_return\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: in user code:\n\n    File \"/usr/local/lib/python3.10/dist-packages/keras/engine/training.py\", line 1284, in train_function  *\n        return step_function(self, iterator)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/engine/training.py\", line 1268, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/usr/local/lib/python3.10/dist-packages/keras/engine/training.py\", line 1249, in run_step  **\n        outputs = model.train_step(data)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/engine/training.py\", line 1050, in train_step\n        y_pred = self(x, training=True)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/utils/traceback_utils.py\", line 70, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"/usr/local/lib/python3.10/dist-packages/keras/engine/input_spec.py\", line 298, in assert_input_compatibility\n        raise ValueError(\n\n    ValueError: Input 0 of layer \"sequential_5\" is incompatible with the layer: expected shape=(None, 5000), found shape=(None, 187)\n"
          ]
        }
      ]
    }
  ]
}